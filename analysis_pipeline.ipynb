{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current developments in the analysis pipeline for the project combined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction for sound analysis of birdsong\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as signal\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_file = '2023_03_31_7_03_30.wav'\n",
    "fs, audio = wavfile.read(sound_file)\n",
    "t_audio = np.linspace(0, len(audio)/fs, num=len(audio))\n",
    "\n",
    "# Bandpass filter the audio signal\n",
    "nyq = 0.5 * fs\n",
    "low = 300 / nyq\n",
    "high = 20000 / nyq\n",
    "order = 5\n",
    "b, a = signal.butter(order, [low, high], btype='band')\n",
    "\n",
    "audio_clip = audio\n",
    "t_audio_clip = np.linspace(0, 5, num=len(audio_clip))\n",
    "ipd.Audio(sound_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, ifft, fftfreq, fftshift\n",
    "window_length = 1323\n",
    "hop_length = 163\n",
    "\n",
    "def calculate_features(x, window_length, hop_length, fs, num_tapers=2):\n",
    "    tapers = signal.windows.dpss(window_length, 1.5, 2)\n",
    "    size = len(x)\n",
    "    f_notShifted = fftfreq(window_length, 1/fs)\n",
    "    f = fftshift(f_notShifted)\n",
    "    f_index = f > 0\n",
    "\n",
    "    sonogram = np.zeros((f_index.sum(), np.floor(size / hop_length).astype(int)))\n",
    "    freq_deriv = np.zeros((f_index.sum(), np.floor(size / hop_length).astype(int)))\n",
    "    time_deriv = np.zeros((f_index.sum(), np.floor(size / hop_length).astype(int)))\n",
    "\n",
    "    goodness_of_fit = np.zeros(np.floor(size / hop_length).astype(int))\n",
    "    frequency_modulation = np.zeros(np.floor(size / hop_length).astype(int))\n",
    "    spectral_derivative = np.zeros((f_index.sum(), np.floor(size / hop_length).astype(int)))\n",
    "    entropy = np.zeros(np.floor(size / hop_length).astype(int))\n",
    "    amplitude = np.zeros(np.floor(size / hop_length).astype(int))\n",
    "\n",
    "    wav_smp = np.arange(size-window_length, step=hop_length).astype(int)\n",
    "    t = np.arange(np.floor(size / hop_length)) *(hop_length/fs)\n",
    "\n",
    "    for i in range(len(wav_smp)):\n",
    "        samps = np.arange(wav_smp[i], np.floor(wav_smp[i] + window_length).astype(int))\n",
    "        window1 = x[samps] * tapers[0]\n",
    "        window2 = x[samps] * tapers[1]\n",
    "\n",
    "        # If the window has values, calculate the cepstrum\n",
    "        if(window1.any()):\n",
    "            real_cepstrum = fftshift(np.real(ifft(np.log10(fft(window1)))))\n",
    "            goodness_of_fit[i] = np.max(real_cepstrum[f_index])\n",
    "        else:\n",
    "            goodness_of_fit[i] = 0\n",
    "        \n",
    "        powSpect1 = fftshift(fft(window1))\n",
    "        powSpect2 = fftshift(fft(window2))\n",
    "\n",
    "        r1 = (np.abs(powSpect1) + np.abs(powSpect2))**2\n",
    "        sonogram[:,i] = r1[f_index]\n",
    "\n",
    "        # Getting time and frequency derivatives\n",
    "        fR1 = np.real(powSpect1[f_index])\n",
    "        fi1 = np.imag(powSpect1[f_index])\n",
    "        fR2 = np.real(powSpect2[f_index])\n",
    "        fi2 = np.imag(powSpect2[f_index])\n",
    "\n",
    "        time_deriv[:,i] = -fR1*fR2 - fi1*fi2\n",
    "        freq_deriv[:,i] = fi1*fR2 - fR1*fi2\n",
    "\n",
    "        # Getting frequnecy modulation\n",
    "        frequency_modulation[i] = np.arctan((np.max(time_deriv[:,i])/np.max(freq_deriv[:,i]))+0.1)\n",
    "\n",
    "        # Solving for spectral derivatives\n",
    "        cFM = np.cos(frequency_modulation[i])\n",
    "        sFM = np.sin(frequency_modulation[i])\n",
    "        spectral_derivative[:,i] = time_deriv[:,i].dot(cFM) + freq_deriv[:,i].dot(sFM)\n",
    "\n",
    "        # Compute entropy\n",
    "        sumLog = np.sum(np.log(sonogram[10:,i])) / (f_index.sum()-10)\n",
    "        sumSon = np.sum(sonogram[10:,i]) / (f_index.sum()-10)\n",
    "        \n",
    "        # Same as -log(sumLog / sumSon)\n",
    "        entropy[i] = (np.log(sumSon - sumLog) / np.log2(f_index.sum() - 10))-1\n",
    "\n",
    "        # Amplitude\n",
    "        amplitude[i] = -10*np.log(sonogram[10:,i]).sum()\n",
    "\n",
    "    return t, f[f_index], sonogram, goodness_of_fit, frequency_modulation, spectral_derivative**2, entropy, amplitude\n",
    "\n",
    "t, f, Sxx, gof, fm, sd, ent, amp = calculate_features(audio_clip, window_length, hop_length, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the syllable start and end times based on crossing a threshold\n",
    "def get_syllables(en, t, threshold, time_threshold=0.05):\n",
    "    # Get the indices of the syllables\n",
    "    syllable_indices = np.where(en > threshold)[0]\n",
    "    \n",
    "    # Get the start and end times of the syllables, combining adjacent frames\n",
    "    syllable_start = [t[syllable_indices[0]]]\n",
    "    syllable_end = []\n",
    "\n",
    "    for i in range(len(syllable_indices)-1):\n",
    "        if syllable_indices[i+1] - syllable_indices[i] > 1:\n",
    "            syllable_end.append(t[syllable_indices[i]])\n",
    "            syllable_start.append(t[syllable_indices[i+1]])\n",
    "\n",
    "    syllable_end.append(t[syllable_indices[-1]])\n",
    "\n",
    "    syllable_start_arr = np.array(syllable_start)\n",
    "    syllable_end_arr = np.array(syllable_end)\n",
    "    duration = syllable_end_arr-syllable_start_arr\n",
    "\n",
    "    return syllable_start_arr[duration > time_threshold], syllable_end_arr[duration > time_threshold]\n",
    "\n",
    "# Get the syllable start and end times\n",
    "syllable_start, syllable_end = get_syllables(ent, t, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe of the syllable audio and start and end times\n",
    "syllables = pd.DataFrame(columns=['start', 'end', 'audio'])\n",
    "\n",
    "for i in range(len(syllable_start)):\n",
    "    start_s = syllable_start[i] # returns time in seconds\n",
    "    start = np.searchsorted(t_audio, start_s)\n",
    "\n",
    "    end_s = syllable_end[i] # returns time in seconds\n",
    "    end = np.searchsorted(t_audio, end_s)\n",
    "\n",
    "    audio_syl = audio[start:end]\n",
    "\n",
    "    syllables.loc[i] = [start_s, end_s, audio_syl]\n",
    "\n",
    "# make all syllables the same length\n",
    "max_length = syllables['audio'].apply(len).max()\n",
    "syllables['audio'] = syllables['audio'].apply(lambda x: np.pad(x, (0, max_length-len(x)), 'constant'))\n",
    "\n",
    "# Get the features for each syllable and add it to the dataframe\n",
    "syllables['t'], syllables['f'], syllables['Sxx'], syllables['gof'], syllables['fm'], syllables['sd'], syllables['ent'], syllables['amp'] = zip(*syllables['audio'].apply(lambda x: calculate_features(x, window_length, hop_length, fs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get minimum syllable length\n",
    "min_window = 14\n",
    "\n",
    "# For each syllable, stack all of the features into a matrix\n",
    "def syllable_feature_matrix(syllables, index):\n",
    "    sg = syllables['Sxx'][index]\n",
    "    sd = np.log10(syllables['sd'][index])\n",
    "    ent = syllables['ent'][index]\n",
    "    gof = syllables['gof'][index]\n",
    "    fm = syllables['fm'][index]\n",
    "    amp = syllables['amp'][index]\n",
    "\n",
    "    # Stack the features into a matrix\n",
    "    feature_matrix = np.vstack((sd, ent, gof, fm, amp)).T\n",
    "    return feature_matrix[:min_window,:]\n",
    "\n",
    "feature_shape = syllable_feature_matrix(syllables, i).flatten()\n",
    "\n",
    "# Get the feature matrix for the first syllable\n",
    "feature_matrix = np.zeros((syllables.shape[0], feature_shape.shape[0]))\n",
    "for i in range(syllables.shape[0]):\n",
    "    feature_matrix[i] = syllable_feature_matrix(syllables, i).flatten()\n",
    "\n",
    "# Replace all nan valuees with 0\n",
    "feature_matrix = np.nan_to_num(feature_matrix,  posinf=33333333, neginf=-33333333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.cluster import Birch\n",
    "\n",
    "clusterable_embedding = umap.UMAP(\n",
    "        n_neighbors=5,\n",
    "        min_dist=0.25,\n",
    "        n_components=2,\n",
    "        metric='canberra',\n",
    "        random_state=42,\n",
    "    ).fit_transform(feature_matrix)\n",
    "\n",
    "clustering = Birch(n_clusters=15)\n",
    "labels = clustering.fit_predict(clusterable_embedding)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "clustered = (labels >= 0)\n",
    "plt.scatter(clusterable_embedding[clustered, 0],\n",
    "            clusterable_embedding[clustered, 1],\n",
    "            c=labels[clustered],\n",
    "            s=5,\n",
    "            cmap='Spectral')\n",
    "\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually go through each cluster and label as a sound or noise, then remove the noise clusters and recluster\n",
    "i = 14\n",
    "syllable_indices = np.where(labels == i)[0]\n",
    "\n",
    "concat = []\n",
    "# Concatenate all of the syllables together\n",
    "for i in syllable_indices:\n",
    "    concat.append(syllables['audio'][i])\n",
    "            \n",
    "\n",
    "# Play in notebook\n",
    "ipd.Audio(np.array(concat).flatten(), rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_clusters = [2,3,4,5,7]\n",
    "clusters = [i for i in range(15) if i not in noise_clusters]\n",
    "\n",
    "# Remove the noise clusters using the indices from the labels\n",
    "idx = [labels in clusters for labels in labels]\n",
    "noiseless_matrix = feature_matrix[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "noiseless_embedding = umap.UMAP(\n",
    "        n_neighbors=3,\n",
    "        min_dist=0.05,\n",
    "        n_components=2,\n",
    "        metric='canberra',\n",
    "        random_state=42,\n",
    "    ).fit_transform(noiseless_matrix)\n",
    "    \n",
    "clustering = KMeans(random_state=42)\n",
    "labels = clustering.fit_predict(noiseless_embedding)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "clustered = (labels >= 0)\n",
    "plt.scatter(noiseless_embedding[clustered, 0],\n",
    "            noiseless_embedding[clustered, 1],\n",
    "            c=labels[clustered],\n",
    "            s=5,\n",
    "            cmap='Spectral')\n",
    "\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually go through each cluster and label as a sound or noise, then remove the noise clusters and recluster\n",
    "i = 1\n",
    "syllable_indices = np.where(labels == i)[0]\n",
    "\n",
    "concat = []\n",
    "# Concatenate all of the syllables together\n",
    "for i in syllable_indices:\n",
    "    concat.append(syllables['audio'][i])\n",
    "            \n",
    "\n",
    "# Play in notebook\n",
    "ipd.Audio(np.array(concat).flatten(), rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdsong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
