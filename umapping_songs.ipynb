{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction for sound analysis of birdsong\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as signal\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_file = 'Data/2023_03_31_7_03_30.wav'\n",
    "fs, audio = wavfile.read(sound_file)\n",
    "t_audio = np.linspace(0, len(audio)/fs, num=len(audio))\n",
    "\n",
    "# Bandpass filter the audio signal\n",
    "nyq = 0.5 * fs\n",
    "low = 300 / nyq\n",
    "high = 20000 / nyq\n",
    "order = 5\n",
    "b, a = signal.butter(order, [low, high], btype='band')\n",
    "\n",
    "audio_clip = audio\n",
    "ipd.Audio(sound_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, ifft, fftfreq, fftshift\n",
    "window_length = 1323\n",
    "hop_length = 163\n",
    "\n",
    "def calculate_features(x, window_length, hop_length, fs, num_tapers=2):\n",
    "    tapers = signal.windows.dpss(window_length, 1.5, 2)\n",
    "    size = len(x)\n",
    "    f_notShifted = fftfreq(window_length, 1/fs)\n",
    "    f = fftshift(f_notShifted)\n",
    "    f_index = f > 0\n",
    "\n",
    "    sonogram = np.zeros((f_index.sum(), np.floor(size / hop_length).astype(int)))\n",
    "    freq_deriv = np.zeros((f_index.sum(), np.floor(size / hop_length).astype(int)))\n",
    "    time_deriv = np.zeros((f_index.sum(), np.floor(size / hop_length).astype(int)))\n",
    "\n",
    "    goodness_of_fit = np.zeros(np.floor(size / hop_length).astype(int))\n",
    "    frequency_modulation = np.zeros(np.floor(size / hop_length).astype(int))\n",
    "    spectral_derivative = np.zeros((f_index.sum(), np.floor(size / hop_length).astype(int)))\n",
    "    entropy = np.zeros(np.floor(size / hop_length).astype(int))\n",
    "    amplitude = np.zeros(np.floor(size / hop_length).astype(int))\n",
    "\n",
    "    wav_smp = np.arange(size-window_length, step=hop_length).astype(int)\n",
    "    t = np.arange(np.floor(size / hop_length)) *(hop_length/fs)\n",
    "\n",
    "    for i in range(len(wav_smp)):\n",
    "        samps = np.arange(wav_smp[i], np.floor(wav_smp[i] + window_length).astype(int))\n",
    "        window1 = x[samps] * tapers[0]\n",
    "        window2 = x[samps] * tapers[1]\n",
    "\n",
    "        # If the window has values, calculate the cepstrum\n",
    "        if(window1.any()):\n",
    "            real_cepstrum = fftshift(np.real(ifft(np.log10(fft(window1)))))\n",
    "            goodness_of_fit[i] = np.max(real_cepstrum[f_index])\n",
    "        else:\n",
    "            goodness_of_fit[i] = 0\n",
    "        \n",
    "        powSpect1 = fftshift(fft(window1))\n",
    "        powSpect2 = fftshift(fft(window2))\n",
    "\n",
    "        r1 = (np.abs(powSpect1) + np.abs(powSpect2))**2\n",
    "        sonogram[:,i] = r1[f_index]\n",
    "\n",
    "        # Getting time and frequency derivatives\n",
    "        fR1 = np.real(powSpect1[f_index])\n",
    "        fi1 = np.imag(powSpect1[f_index])\n",
    "        fR2 = np.real(powSpect2[f_index])\n",
    "        fi2 = np.imag(powSpect2[f_index])\n",
    "\n",
    "        time_deriv[:,i] = -fR1*fR2 - fi1*fi2\n",
    "        freq_deriv[:,i] = fi1*fR2 - fR1*fi2\n",
    "\n",
    "        # Getting frequnecy modulation\n",
    "        frequency_modulation[i] = np.arctan((np.max(time_deriv[:,i])/np.max(freq_deriv[:,i]))+0.1)\n",
    "\n",
    "        # Solving for spectral derivatives\n",
    "        cFM = np.cos(frequency_modulation[i])\n",
    "        sFM = np.sin(frequency_modulation[i])\n",
    "        spectral_derivative[:,i] = time_deriv[:,i].dot(cFM) + freq_deriv[:,i].dot(sFM)\n",
    "\n",
    "        # Compute entropy\n",
    "        sumLog = np.sum(np.log(sonogram[10:,i])) / (f_index.sum()-10)\n",
    "        sumSon = np.sum(sonogram[10:,i]) / (f_index.sum()-10)\n",
    "        \n",
    "        # Same as -log(sumLog / sumSon)\n",
    "        entropy[i] = (np.log(sumSon - sumLog) / np.log2(f_index.sum() - 10))-1\n",
    "\n",
    "        # Amplitude\n",
    "        amplitude[i] = -10*np.log(sonogram[10:,i]).sum()\n",
    "\n",
    "    return t, f[f_index], sonogram, goodness_of_fit, frequency_modulation, spectral_derivative**2, entropy, amplitude\n",
    "\n",
    "t, f, Sxx, gof, fm, sd, ent, amp = calculate_features(audio_clip, window_length, hop_length, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152419 1133483\n"
     ]
    }
   ],
   "source": [
    "# Only include Sxx indices where the ent value is above 0.4\n",
    "sounds = sd[:,ent >= 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "clusterable_embedding = umap.UMAP(\n",
    "        n_neighbors=50,\n",
    "        min_dist=0.5,\n",
    "        n_components=2,\n",
    "        metric='canberra',\n",
    "        n_jobs=-1,\n",
    "        ).fit_transform(sounds.T)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(clusterable_embedding[:, 0],\n",
    "            clusterable_embedding[:, 1],\n",
    "            s=1,\n",
    "            alpha=0.1,\n",
    "            color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a video over the umap embedding, where the point on the graph changes color when it is played in the audio\n",
    "# Variables used: t, clusterable_embedding, ent\n",
    "\n",
    "# Make the graphic 30 fps\n",
    "fps = 30\n",
    "video_t = np.arange(0, t[-1], 1/fps)\n",
    "num_frames = 30*60\n",
    "\n",
    "idx_buffer = []\n",
    "buffer_counter = []\n",
    "buffer_thresh = 10\n",
    "\n",
    "for i in range(num_frames): #range(len(video_t)):\n",
    "    # Find the index of the closest point to the current time\n",
    "    plt.scatter(clusterable_embedding[:, 0],\n",
    "                clusterable_embedding[:, 1],\n",
    "                color='black',\n",
    "                s=1,\n",
    "                alpha=0.1)\n",
    "\n",
    "    idx = np.argwhere(np.abs(t - video_t[i]) < 1/fps)\n",
    "    idx = [x in idx if ent[x] >= 0.4]\n",
    "\n",
    "    idx_buffer.append(idx)\n",
    "    buffer_counter.append(np.zeros(len(idx)))\n",
    "\n",
    "    plt.scatter(clusterable_embedding[idx, 0],\n",
    "                clusterable_embedding[idx, 1],\n",
    "                s=5,\n",
    "                color='blue')\n",
    "    plt.ylim([0, 20])\n",
    "    plt.xlim([-7.5, 15])\n",
    "    plt.axis('off')\n",
    "    plt.savefig('Data/umap_video/' + str(i) + '.png')\n",
    "    plt.clf()\n",
    "\n",
    "#     idx_buffer = idx_buffer[old_buffer]\n",
    "#     buffer_counter = buffer_counter[old_buffer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the images from the umap_video folder and make a video\n",
    "import cv2\n",
    "\n",
    "img_array = []\n",
    "for i in range(num_frames):\n",
    "    filename = 'Data/umap_video/' + str(i) + '.png'\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "out = cv2.VideoWriter('Data/umap_video/umap_video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 30, size)\n",
    "\n",
    "# Save video\n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdsong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
