{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction for sound analysis of birdsong\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as signal\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_file = 'Data/2023_03_31_7_03_30.wav'\n",
    "fs, audio = wavfile.read(sound_file)\n",
    "t_audio = np.linspace(0, len(audio)/fs, num=len(audio))\n",
    "\n",
    "# Bandpass filter the audio signal\n",
    "nyq = 0.5 * fs\n",
    "low = 300 / nyq\n",
    "high = 20000 / nyq\n",
    "order = 5\n",
    "b, a = signal.butter(order, [low, high], btype='band')\n",
    "\n",
    "audio_clip = audio\n",
    "ipd.Audio(sound_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SAP_features as SAP\n",
    "\n",
    "# Get the entropy of the wav file using a sliding window\n",
    "window_size = 1323\n",
    "window_step = 165\n",
    "\n",
    "sap = SAP.SAP_features(audio, fs, window_size, window_step)\n",
    "ent = sap.entropy\n",
    "sd = sap.spectral_derivative\n",
    "\n",
    "# Only include Sxx indices where the ent value is above 0.4\n",
    "sounds = sd[:,ent >= 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "clusterable_embedding = umap.UMAP(\n",
    "        n_neighbors=50,\n",
    "        min_dist=0.5,\n",
    "        n_components=2,\n",
    "        metric='canberra',\n",
    "        n_jobs=-1,\n",
    "        ).fit_transform(sounds.T)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(clusterable_embedding[:, 0],\n",
    "            clusterable_embedding[:, 1],\n",
    "            s=1,\n",
    "            alpha=0.1,\n",
    "            color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a video over the umap embedding, where the point on the graph changes color when it is played in the audio\n",
    "# Variables used: t, clusterable_embedding, ent\n",
    "\n",
    "# Make the graphic 30 fps\n",
    "fps = 30\n",
    "video_t = np.arange(0, t[-1], 1/fps)\n",
    "num_frames = 30*60\n",
    "\n",
    "idx_buffer = []\n",
    "buffer_counter = []\n",
    "buffer_thresh = 10\n",
    "\n",
    "for i in range(num_frames): #range(len(video_t)):\n",
    "    # Find the index of the closest point to the current time\n",
    "    plt.scatter(clusterable_embedding[:, 0],\n",
    "                clusterable_embedding[:, 1],\n",
    "                color='black',\n",
    "                s=1,\n",
    "                alpha=0.1)\n",
    "\n",
    "    idx = np.argwhere(np.abs(t - video_t[i]) < 1/fps)\n",
    "    idx = [x in idx if ent[x] >= 0.4]\n",
    "\n",
    "    idx_buffer.append(idx)\n",
    "    buffer_counter.append(np.zeros(len(idx)))\n",
    "\n",
    "    plt.scatter(clusterable_embedding[idx, 0],\n",
    "                clusterable_embedding[idx, 1],\n",
    "                s=5,\n",
    "                color='blue')\n",
    "    plt.ylim([0, 20])\n",
    "    plt.xlim([-7.5, 15])\n",
    "    plt.axis('off')\n",
    "    plt.savefig('Data/umap_video/' + str(i) + '.png')\n",
    "    plt.clf()\n",
    "\n",
    "#     idx_buffer = idx_buffer[old_buffer]\n",
    "#     buffer_counter = buffer_counter[old_buffer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the images from the umap_video folder and make a video\n",
    "import cv2\n",
    "\n",
    "img_array = []\n",
    "for i in range(num_frames):\n",
    "    filename = 'Data/umap_video/' + str(i) + '.png'\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "out = cv2.VideoWriter('Data/umap_video/umap_video.avi', cv2.VideoWriter_fourcc(*'DIVX'), 30, size)\n",
    "\n",
    "# Save video\n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdsong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
